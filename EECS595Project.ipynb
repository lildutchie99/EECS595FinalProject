{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EECS595ProjectSubmissionVersion",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIty899aYac8"
      },
      "source": [
        "#ONLY IF RUNNING IN COLAB USING TRIP_PARSES FROM DRIVE\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# !cp /content/drive/MyDrive/trip_parses.json /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbnVv5lzY-r4"
      },
      "source": [
        "!pip install neuralcoref spacy==2.1.0\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbixMQQPYMoL"
      },
      "source": [
        "!git clone https://github.com/sled-group/Verifiable-Coherent-NLU.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5FZSEo5VzHo"
      },
      "source": [
        "import json\n",
        "import copy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import random\n",
        "import neuralcoref\n",
        "import scipy.stats\n",
        "from collections import Counter\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "neuralcoref.add_to_pipe(nlp)\n",
        "\n",
        "attrs = [\"temperature\", \"clean\", \"h_wet\", \"mixed\", \"hygiene\", \"wearing\", \"contain\", \"wet\", \"solid\", \"edible\", \"pieces\", \"moveable\", \"power\", \"exist\", \"functional\", \"conscious\", \"running\", \"open\"]\n",
        "NATTRS = len(attrs)\n",
        "#\"location\", \"h_location\"\n",
        "\n",
        "sc_to_precond = ['_', 'f', 't', 't', 'f', '_', '_', 'f', 't']\n",
        "sc_to_effect = ['_', 'f', 't', 'f', 't', 'f', 't', '_', '_']\n",
        "\n",
        "attr_defaults = {attr: ('t' if attr in {'conscious', 'functional', 'exist', 'moveable'} else '_') for attr in attrs}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7jON6WbV1dW"
      },
      "source": [
        "with open('Verifiable-Coherent-NLU/all_data/www.json') as f:\n",
        "  trip = json.load(f)\n",
        "with open('trip_parses.json') as f:\n",
        "  parses = json.load(f)\n",
        "\n",
        "for spl in list(trip.keys()):\n",
        "  for suid in list(trip[spl].keys()):\n",
        "    if 'states' not in trip[spl][suid] or trip[spl][suid]['length'] != len(trip[spl][suid]['states']) or trip[spl][suid]['length'] != len(trip[spl][suid]['sentences']):\n",
        "      del trip[spl][suid]\n",
        "\n",
        "test_aug = trip['test'].copy()\n",
        "negkeys = [x for x in test_aug if '-' not in x]\n",
        "numneg = len(negkeys)\n",
        "numpos = len(test_aug) - numneg\n",
        "for i in range(numpos - numneg):\n",
        "  newk = random.choice(negkeys)\n",
        "  i = 0\n",
        "  while 1:\n",
        "    if (newk + '_' + str(i)) not in test_aug: break\n",
        "    i += 1\n",
        "  test_aug[newk + '_' + str(i)] = test_aug[newk].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am1rT_Qwa8_X"
      },
      "source": [
        "def filter_state_changes(dstate, obj):\n",
        "  rule_sc = []\n",
        "  for attr, changes in dstate.items():\n",
        "    for cobj, sc in changes:\n",
        "      if cobj == obj and sc != 0:\n",
        "        rule_sc.append((attr, sc))\n",
        "  return rule_sc\n",
        "\n",
        "def get_sc(dstate, obj, attr):\n",
        "  if attr not in dstate: return 0\n",
        "  for cobj, sc in dstate[attr]:\n",
        "    if obj in cobj: return sc\n",
        "  return 0\n",
        "\n",
        "def spacy_is_ancestor(anc, child):\n",
        "  while 1:\n",
        "    if child == anc: return True\n",
        "    if child == child.head: return False\n",
        "    child = child.head"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnQadB0_gZJH"
      },
      "source": [
        "#Rule Class/Prototype Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zws5_Cm2gco8"
      },
      "source": [
        "rule_protos = []\n",
        "spacy_cache = {}\n",
        "\n",
        "for suid, story in trip['train'].items():\n",
        "  for sentidx in range(story['length']):\n",
        "    sentence = story['sentences'][sentidx]\n",
        "    dstate = story['states'][sentidx]\n",
        "    parse = parses[sentence]\n",
        "\n",
        "    tracked_objects = set(story['objects'].split(', '))\n",
        "    for sc in dstate.values():\n",
        "      tracked_objects |= set([x[0] for x in sc])\n",
        "\n",
        "    if sentence in spacy_cache: \n",
        "      doc = spacy_cache[sentence]\n",
        "    else:\n",
        "      doc = nlp(sentence)\n",
        "      spacy_cache[sentence] = doc\n",
        "\n",
        "    head_idx_to_chunk = {x.root.i: x for x in doc.noun_chunks}\n",
        "    for chunk in doc.noun_chunks:\n",
        "      obj = None\n",
        "      for x in tracked_objects:\n",
        "        if x in chunk.text:\n",
        "          obj = x\n",
        "          break\n",
        "      if not obj: continue #this means this chunk isn't a tracked object\n",
        "      \n",
        "      head_start, head_end, headdep = None,None,None\n",
        "      for src, dst, dep in parse: #find predicate (assume direct head)\n",
        "        if dst-1 == chunk.root.i and doc[src-1].tag_.startswith('VB'):\n",
        "          head_start = src-1\n",
        "          head_end = head_start+1\n",
        "          while head_end < len(doc) and doc[head_end].dep_ == 'prt': head_end += 1 #expand for phrasal verbs\n",
        "          headdep = dep\n",
        "          break\n",
        "\n",
        "      if not headdep: continue\n",
        "\n",
        "      aux_deps = []\n",
        "      for src, dst, dep in parse: #find auxiliary dependants of predicate\n",
        "        if src-1 == head_start and dst-1 != chunk.root.i and dst-1 in head_idx_to_chunk:\n",
        "          aux_deps.append((dep, head_idx_to_chunk[dst-1].text))\n",
        "\n",
        "      rule_crit = [doc[head_start:head_end].text, headdep, aux_deps] #(pred, target_dep, [(dep, head), ...])\n",
        "\n",
        "      rule_sc = filter_state_changes(dstate, obj)\n",
        "\n",
        "      # print()\n",
        "      # print(rule_crit)\n",
        "      # print(rule_sc)\n",
        "      rule_protos.append((rule_crit, rule_sc, sentence))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPyj3y4_gjXq"
      },
      "source": [
        "print(random.choice(rule_protos))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Get thist and rcrules\n",
        "thist[ruleclass][attr][auxpair] = [0, 0, 0, 6, 6, 3, 0...] = (list of sc's)\n",
        "\n",
        "rcrules[ruleclass][auxpair] = {(attr1, sc1), ...} (used ONLY in non-prob version)"
      ],
      "metadata": {
        "id": "IIJUa3788o4z"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Alv_yrouJ3S_"
      },
      "source": [
        "thist = {}\n",
        "\n",
        "for crit, sc, sent in rule_protos:\n",
        "  pred, hdep, auxdep = crit\n",
        "\n",
        "  #rattrs = {a: {} for a in attrs}\n",
        "  for sattr in attrs:\n",
        "    #if sattr not in rattrs: rattrs[sattr] = {}\n",
        "    sctl = [x[1] for x in sc if x[0] == sattr] #get sct\n",
        "    if sctl: sct = sctl[0]\n",
        "    else: sct = 0\n",
        "\n",
        "    #if auxdep and pred == 'put' and hdep == 'obj': print('start')\n",
        "    #hist = {}\n",
        "    if (pred, hdep) not in thist: thist[(pred, hdep)] = {}\n",
        "    if sattr not in thist[(pred, hdep)]: thist[(pred, hdep)][sattr] = {}\n",
        "    hist = thist[(pred, hdep)][sattr]\n",
        "\n",
        "    for adep, aobj in auxdep:\n",
        "      if adep == 'nsubj': continue #usually not relevant\n",
        "\n",
        "      hn = (adep, aobj)\n",
        "      if hn not in hist: hist[hn] = []\n",
        "      hist[hn].append(sct)\n",
        "\n",
        "      if (adep, '*') not in hist: hist[(adep, '*')] = []\n",
        "      hist[(adep, '*')].append(sct)\n",
        "\n",
        "      if ('*', '*') not in hist: hist[('*', '*')] = []\n",
        "      hist[('*', '*')].append(sct)\n",
        "\n",
        "      #if pred == 'put' and hdep == 'obj': print(adep, aobj, hist)\n",
        "\n",
        "    #if hist: rattrs[sattr] = hist\n",
        "  #thist[(pred, hdep)] = rattrs\n",
        "\n",
        "rcrules = {}\n",
        "for rp, rattrs in thist.items():\n",
        "  rcrule = {}\n",
        "  for attr, hist in rattrs.items():\n",
        "    for k, v in hist.items():\n",
        "      mcsc, mccount = Counter(v).most_common(1)[0]\n",
        "      if mcsc != 0: #and mccount/len(v) > 0.9\n",
        "        if k not in rcrule: rcrule[k] = set()\n",
        "        rcrule[k].add((attr, mcsc))\n",
        "\n",
        "  for k in list(rcrule.keys()): #remove redundancies\n",
        "      if ('*', '*') in rcrule and k != ('*', '*'):\n",
        "        rcrule[k] -= rcrule[('*', '*')]\n",
        "      if k[1] != '*' and (k[0], '*') in rcrule:\n",
        "        rcrule[k] -= rcrule[(k[0], '*')]\n",
        "      if not rcrule[k]: del rcrule[k]\n",
        "  if rcrule: rcrules[rp] = rcrule\n",
        "\n",
        "# # print([(k, set(v), scipy.stats.entropy(list(Counter(v).values())), len(v)) for k, v in hist.items() if any(v)]) #ignore those with no SC\n",
        "# # print([(k, set(v), scipy.stats.entropy(list(Counter(v).values())), len(v)) for k, v in histwc.items() if any(v)])\n",
        "# print([(k, set(v), {k2: x/len(v) for k2, x in Counter(v).items()}, len(v)) for k, v in hist.items() if any(v)]) #ignore those with no SC\n",
        "# #print([(k, set(v), {k2: x/len(v) for k2, x in Counter(v).items()}, len(v)) for k, v in histwc.items() if any(v)])\n",
        "\n",
        "print(thist[('put', 'obj')])\n",
        "print(rcrules[('put', 'obj')])\n",
        "print()\n",
        "\n",
        "print(thist[('washed', 'obj')])\n",
        "print(rcrules.keys())\n",
        "print(rcrules[('washed', 'obj')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Predict prob state changes"
      ],
      "metadata": {
        "id": "PNWBuKoQmNtM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6V0QTtUEOYy"
      },
      "source": [
        "def prob_scs_for_dataset(dataset, rules):\n",
        "\n",
        "  num_total, num_correct = 0, 0\n",
        "\n",
        "  res = {}\n",
        "\n",
        "  for suid, story in dataset.items():\n",
        "    \n",
        "    tracked_objects = {x.strip() for x in story['objects'].split(',') if x.strip()} | {ob for sent in story['states'] for attrchanges in sent.values() for ob, _ in attrchanges}\n",
        "\n",
        "    story_scs = []\n",
        "    for sentidx, sentence in enumerate(story['sentences']):\n",
        "      sent_scs = {}\n",
        "\n",
        "      dstate = story['states'][sentidx]\n",
        "      parse = parses[sentence]\n",
        "\n",
        "      #doc = spacy_cache[sentence]\n",
        "      if sentence in spacy_cache: \n",
        "        doc = spacy_cache[sentence]\n",
        "      else:\n",
        "        doc = nlp(sentence)\n",
        "        spacy_cache[sentence] = doc\n",
        "\n",
        "      if max(parse, key=lambda x: x[1])[1]-1 >= len(doc): #tokenization disagreement between spacy and corenlp (hyphen)\n",
        "        story_scs.append({ob: {attr: np.array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0]) for attr in attrs} for ob in tracked_objects})\n",
        "        continue\n",
        "\n",
        "      head_idx_to_chunk = {x.root.i: x for x in doc.noun_chunks}\n",
        "\n",
        "      for chunk in doc.noun_chunks:    \n",
        "        obj = None\n",
        "        for x in tracked_objects:\n",
        "          # if (x not in chunk.text) and (chunk._.coref_cluster and x in chunk._.coref_cluster.main.text):\n",
        "          #   print('successful coref:', chunk._.coref_cluster.main, chunk, sentence)\n",
        "          if (x in chunk.text) or (chunk._.coref_cluster and x in chunk._.coref_cluster.main.text):\n",
        "            obj = x\n",
        "            break\n",
        "\n",
        "        if not obj: continue #this means this chunk isn't a tracked object\n",
        "\n",
        "        predicted_scs = {attr: np.zeros(9, dtype=np.float32) for attr in attrs} #for this object\n",
        "\n",
        "        head_start, head_end, headdep = None,None,None\n",
        "        for src, dst, dep in parse: #find predicate (assume direct head)\n",
        "          #Below does not account for cases where larger noun phrase refers to object (eg \"the rest of the milk\")\n",
        "          #if dst-1 != chunk.root.i: continue #edge destination is not target\n",
        "          if not spacy_is_ancestor(doc[dst-1], chunk.root): continue\n",
        "\n",
        "          head_start = src-1\n",
        "          head_end = head_start+1\n",
        "          while head_end < len(doc) and doc[head_end].dep_ == 'prt': head_end += 1 #expand for phrasal verbs\n",
        "          pred = doc[head_start:head_end].text\n",
        "\n",
        "          if (pred, dep) in rules: #matches rule prototype\n",
        "            rcrule = rules[(pred, dep)]\n",
        "\n",
        "            aux_match = ('*', '*') if ('*', '*') in rcrule.keys() else None #0 = no match, 1 = (*,*), 2 = (-,*), 3 = (-,-)\n",
        "            for src2, dst2, dep2 in parse: #find a relevant edge for this auxdep\n",
        "              for auxdep, auxval in rcrule.keys(): #FIX dep2=='*'\n",
        "                if not (src2-1 == head_start and dep2 == auxdep): continue\n",
        "\n",
        "                #if suid == '26-C0' and obj == 'milk':\n",
        "                #  print((pred, dep), obj, (auxdep, auxval), head_idx_to_chunk[dst2-1].text if dst2-1 in head_idx_to_chunk else auxval == doc[dst2-1].text)\n",
        "\n",
        "                if auxval == '*':\n",
        "                  if aux_match[0] == '*': aux_match = (auxdep, auxval)\n",
        "                elif (auxval == head_idx_to_chunk[dst2-1].text if dst2-1 in head_idx_to_chunk else auxval == doc[dst2-1].text): #bad workaround for tokenizing differences between corenlp and spacy\n",
        "                  #if suid == '26-C0' and obj == 'milk': print('BIG MATCH!!')\n",
        "                  aux_match = (auxdep, auxval)\n",
        "                  break\n",
        "            #if suid == '26-C0' and obj == 'milk': print(aux_match)\n",
        "            if aux_match:\n",
        "              for attr, ctr in rcrule[aux_match].items():\n",
        "                cnts = np.array([ctr[x] for x in range(9)], dtype=np.float32)\n",
        "                predicted_scs[attr] += cnts/(cnts.sum() + 1e-6)\n",
        "        for attr in attrs:\n",
        "          if not any(predicted_scs[attr]): del predicted_scs[attr]\n",
        "          else: predicted_scs[attr] /= predicted_scs[attr].sum()\n",
        "        sent_scs[obj] = predicted_scs\n",
        "      story_scs.append(sent_scs)\n",
        "    res[suid] = story_scs\n",
        "  return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcG_2N08vZG5"
      },
      "source": [
        "#thist_cnt = {rc: {attr: {auxtup: Counter(hist) for auxtup, hist in attrhist.items() if any(hist)} for attr, attrhist in rchist.items()} for rc, rchist in thist.items()}\n",
        "#thist_cnt[('bought', 'obj')]\n",
        "\n",
        "thist_cnt = {}\n",
        "for rc, rchist in thist.items():\n",
        "  thist_cnt[rc] = {}\n",
        "  for attr, attrhist in rchist.items():\n",
        "    for auxtup, hist in attrhist.items():\n",
        "      if any(hist): #ignore if all 0's/irrelevant\n",
        "        if auxtup not in thist_cnt[rc]: thist_cnt[rc][auxtup] = {}\n",
        "        thist_cnt[rc][auxtup][attr] = Counter(hist)\n",
        "\n",
        "prob_scs = prob_scs_for_dataset(trip['test'], thist_cnt) #prob_scs[storyid][sentidx][obj][attr] = distribution"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Precision and recall for state change predictor"
      ],
      "metadata": {
        "id": "c5us7thTPjiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct, total = 0, 0\n",
        "\n",
        "gt = set()\n",
        "gtprec, gteff = set(), set()\n",
        "for suid, story in trip['test'].items():\n",
        "  for i, sent in enumerate(story['states']):\n",
        "    for attr, attrscs in sent.items():\n",
        "      if attr not in attrs: continue\n",
        "      for obj, sc in attrscs:\n",
        "        if sc != 0: \n",
        "          gt.add((suid, i, obj, attr, sc))\n",
        "          if sc_to_precond[sc] != '_': gtprec.add((suid, i, obj, attr, sc_to_precond[sc]))\n",
        "          if sc_to_effect[sc] != '_': gteff.add((suid, i, obj, attr, sc_to_effect[sc]))\n",
        "\n",
        "pscs = set()\n",
        "pscprec, psceff = set(), set()\n",
        "for suid, story in prob_scs.items():\n",
        "  for i, sent in enumerate(story):\n",
        "    for obj, objattrs in sent.items():\n",
        "      for attr, scdist in objattrs.items():\n",
        "        sc = np.argmax(scdist)\n",
        "        if sc != 0: \n",
        "          pscs.add((suid, i, obj, attr, sc))\n",
        "          if sc_to_precond[sc] != '_': pscprec.add((suid, i, obj, attr, sc_to_precond[sc]))\n",
        "          if sc_to_effect[sc] != '_': psceff.add((suid, i, obj, attr, sc_to_effect[sc]))\n",
        "\n",
        "fps = pscs - gt\n",
        "fns = gt - pscs\n",
        "tps = gt & pscs\n",
        "\n",
        "print('overall states:')\n",
        "print('\\tprec:', len(tps)/(len(tps) + len(fps)))\n",
        "print('\\trec:', len(tps)/(len(tps) + len(fns)))\n",
        "\n",
        "fpsprec = pscprec - gtprec\n",
        "fnsprec = gtprec - pscprec\n",
        "tpsprec = gtprec & pscprec\n",
        "\n",
        "print('preconditions:')\n",
        "print('\\tprec:', len(tpsprec)/(len(tpsprec) + len(fpsprec)))\n",
        "print('\\trec:', len(tpsprec)/(len(tpsprec) + len(fnsprec)))\n",
        "\n",
        "fpseff = psceff - gteff\n",
        "fnseff = gteff - psceff\n",
        "tpseff = gteff & psceff\n",
        "\n",
        "print('effects:')\n",
        "print('\\tprec:', len(tpseff)/(len(tpseff) + len(fpseff)))\n",
        "print('\\trec:', len(tpseff)/(len(tpseff) + len(fnseff)))"
      ],
      "metadata": {
        "id": "blcMifMsL46f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prob story sim"
      ],
      "metadata": {
        "id": "iH6sNTbom0TA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def story_sim(story_scs, objs, actor):\n",
        "  objs = set(objs) | set([ob for sent in story_scs for ob in sent])\n",
        "  # for o in [ob for sent in story_scs for ob in sent]:\n",
        "  #   if not any([x in o for x in objs]):\n",
        "  #     objs.add(o)\n",
        "  objs.discard('')\n",
        "  #print(objs)\n",
        "  \n",
        "  states = [{ob: {attr: [1.0 if attr in {'conscious', 'exist', 'functional', 'moveable'} else 0.5, np.array([1.0] + [0.0]*len(story_scs)), '_', '_'] for attr in attrs} for ob in objs}] #last element = attribute was assumed (no affector)\n",
        "  #below: potentially redudant??\n",
        "  states[0][actor] = {attr: [1.0 if attr in {'conscious', 'exist', 'functional', 'moveable'} else 0.5, np.array([1.0] + [0.0]*len(story_scs)), '_', '_'] for attr in attrs}\n",
        "\n",
        "  cfprobs = {}\n",
        "  for i, scst in enumerate(story_scs):\n",
        "    #print(states['milk']['exist'])\n",
        "    states.append(copy.deepcopy(states[i]))\n",
        "\n",
        "    for ob, ob_scs in scst.items():\n",
        "      for attr, sc in ob_scs.items():\n",
        "        if 'location' in attr: continue #ignore location for now\n",
        "\n",
        "        if ob not in objs:\n",
        "          for o in objs:\n",
        "            if o in ob or ob in o: ob = o\n",
        "        st = states[i][ob][attr][0]\n",
        "\n",
        "        pcneg = sc[1] + sc[4] + sc[7]\n",
        "        pcpos = sc[2] + sc[3] + sc[8]\n",
        "        pcnone = sc[0] + sc[5] + sc[6]\n",
        "\n",
        "        effneg = sc[1] + sc[3] + sc[5]\n",
        "        effpos = sc[2] + sc[4] + sc[6]\n",
        "        effunk = sc[7] + sc[8] #unknown (probability = 0.5)\n",
        "        effna = sc[0] #irrelevant (probability = passthrough)\n",
        "\n",
        "        cfprobs[(i, ob, attr)] = pcpos*(1 - st) + pcneg*st\n",
        "\n",
        "        states[i+1][ob][attr][0] = effpos + 0.5*effunk + states[i][ob][attr][0]*effna #1.0*effpos + 0.0*effneg + 0.5*effunk + <last state>*effna\n",
        "        states[i+1][ob][attr][1] *= effna #probability of affectors being previous sentences multiplied by likelihood of passthrough \n",
        "        states[i+1][ob][attr][1][i+1] = 1 - effna\n",
        "        states[i+1][ob][attr][2] = ['f', 't', '_'][np.argmax([pcneg, pcpos, pcnone])]\n",
        "        states[i+1][ob][attr][3] = ['f', 't', '_'][np.argmax([effneg, effpos, effunk+effna])]\n",
        "  #print(states['milk']['exist'])\n",
        "  return cfprobs, states\n",
        "\n",
        "def get_best_conflict(cfprobs_src, states_src, cfprobs_other):\n",
        "  if not cfprobs_src:\n",
        "    return None, 0, 0\n",
        "  for cfcause, cprob in sorted(cfprobs_src.items(), key=lambda x: x[1], reverse=True):\n",
        "    #if (cfcause, cprob) in cfprobs_other.items(): continue #ignore if also present in other story\n",
        "\n",
        "    bp, bpobj, bpattr = cfcause\n",
        "    #if bp == 0: continue\n",
        "\n",
        "    evidence = np.argmax(states_src[bp][bpobj][bpattr][1])\n",
        "    if evidence == 0: continue #if evidence is defaults, ignore\n",
        "\n",
        "    cf1cause, cf1max = cfcause, cprob\n",
        "    cf1ev = evidence\n",
        "    return cf1cause, cf1max, cf1ev\n",
        "\n",
        "  #print('no good conflict found')\n",
        "  cf1cause, cf1max = max(cfprobs_src.items(), key=lambda x: x[1])\n",
        "  bp, bpobj, bpattr = cf1cause \n",
        "  ev = np.argmax(states_src[bp][bpobj][bpattr][1])\n",
        "  return cf1cause, cf1max, ev\n",
        "\n",
        "def which_is_plaus(res1, res2): #returns which one is PLAUSIBLE\n",
        "  cfprobs1, states1 = res1\n",
        "  cfprobs2, states2 = res2\n",
        "\n",
        "  plaus_story = 0\n",
        "\n",
        "  cf1cause, cf1max, cf1ev = get_best_conflict(cfprobs1, states1, cfprobs2)\n",
        "  cf2cause, cf2max, cf2ev = get_best_conflict(cfprobs2, states2, cfprobs1)\n",
        "\n",
        "  if not cf1cause: return 1, 0, 0, (None, None, '_'), (None, None, '_')\n",
        "  if not cf2cause: return 2, 0, 0, (None, None, '_'), (None, None, '_')\n",
        "\n",
        "  plaus_story = 1 if cf1max < cf2max else 2 #if max conflict likelihood is lower for cf1, say it is plausible\n",
        "  i_cause, i_max, i_ev, i_states = (cf2cause, cf2max, cf2ev, states2) if cf1max < cf2max else (cf1cause, cf1max, cf1ev, states1) \n",
        "  i_bp, i_bpobj, i_bpattr = i_cause\n",
        "\n",
        "  bpprecond = i_states[i_bp+1][i_bpobj][i_bpattr][2] #plus one because first entry is before anything - NOT ANYMORE!!\n",
        "  eveffect = i_states[i_ev][i_bpobj][i_bpattr][3]\n",
        "\n",
        "  return plaus_story, i_bp, i_ev, (i_bpobj, i_bpattr, bpprecond), (i_bpobj, i_bpattr, eveffect)"
      ],
      "metadata": {
        "id": "NlSaikYscpjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Use ground truth state labels"
      ],
      "metadata": {
        "id": "-mbpivZh57VN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#use ground truth state labels\n",
        "#prob_scs[storyid][sentidx][obj][attr] = distribution\n",
        "gt_prob_scs = {suid: [{obj: {attr: np.eye(9)[get_sc(sentstates, obj, attr)] for attr in attrs} for obj in {o for p in sentstates.values() for o, _ in p}} for sentstates in story['states']] for suid, story in trip['test'].items()}\n",
        "#print(prob_scs['100'][0])"
      ],
      "metadata": {
        "id": "z7CSWKf1J-Hu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Get set of stories with at least one evidence-breakpoint conflict"
      ],
      "metadata": {
        "id": "qCFweyXhP3Yr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#determine how many sentences are actually verifiable with conflicting state changes\n",
        "\n",
        "verf_stories = dict()\n",
        "\n",
        "nevverf, nstoryverf, evtot, storytot = 0, 0, 0, 0\n",
        "for suid, story in trip['test'].items():\n",
        "  if story['plausible']: continue\n",
        "\n",
        "  bp = story['breakpoint']\n",
        "  bpscs = {attr: dict(attrscs) for attr, attrscs in story['states'][bp].items()}\n",
        "\n",
        "  storyverf = False\n",
        "  for ev in story['confl_sents']:\n",
        "    evverf = False #if there is any conflict for this evidence\n",
        "    for attr in attrs:\n",
        "      for ob, evsc in story['states'][ev][attr]:\n",
        "        if evsc == 0: continue #if doesn't affect attribute, can't be evidence\n",
        "        if ob not in bpscs[attr]: continue #if breakpoint doesn't care about object, can't be evidence\n",
        "\n",
        "        prec = sc_to_precond[bpscs[attr][ob]]\n",
        "        if prec == '_': continue #if no precondition, can't be conflict for this (attr,ob)\n",
        "\n",
        "        if sc_to_effect[evsc] != prec:\n",
        "          evverf = True\n",
        "          break\n",
        "      if evverf: break\n",
        "    if evverf:\n",
        "      storyverf = True\n",
        "      nevverf += 1\n",
        "    evtot += 1\n",
        "  if storyverf:\n",
        "    nstoryverf += 1\n",
        "    verf_stories[suid] = story\n",
        "  storytot += 1\n",
        "\n",
        "print(nevverf/evtot)\n",
        "print(nstoryverf/storytot)"
      ],
      "metadata": {
        "id": "rebO0-_XMUei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Simulate!"
      ],
      "metadata": {
        "id": "_OswwR-X59WS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "USE_GROUND_TRUTH_STATE_CHANGES = False\n",
        "USE_REFINED_TEST_SET = False\n",
        "\n",
        "if USE_REFINED_TEST_SET:\n",
        "  #use only stories that have a state confict between evidence and breakpoint\n",
        "  spl = copy.deepcopy(verf_stories)\n",
        "  spl.update({suid: story for suid, story in trip['test'].items() if story['plausible']})\n",
        "else:\n",
        "  spl = trip['test']\n",
        "\n",
        "sim_prob_scs = gt_prob_scs if USE_GROUND_TRUTH_STATE_CHANGES else prob_scs\n",
        "\n",
        "spairs = {p: [q for q in spl.keys() if q.startswith(p + '-')] for p in spl.keys() if '-' not in p}\n",
        "\n",
        "correct, consis, verif, total = 0, 0, 0, 0\n",
        "\n",
        "random.seed(73)\n",
        "\n",
        "for plaus_id, confl_ids in spairs.items():\n",
        "  p_res = story_sim(sim_prob_scs[plaus_id], [x.strip() for x in spl[plaus_id]['objects'].split(',')], spl[plaus_id]['actor'])\n",
        "  for confl_id in confl_ids:\n",
        "    c_res = story_sim(sim_prob_scs[confl_id], [x.strip() for x in spl[confl_id]['objects'].split(',')], spl[confl_id]['actor'])\n",
        "\n",
        "    correct_answer = 1 if random.random() < 0.5 else 2\n",
        "\n",
        "    pred_plaus, bp, ev, bpprecond, eveffect = which_is_plaus(p_res if correct_answer==1 else c_res, p_res if correct_answer==2 else c_res) \n",
        "\n",
        "    bpprecondobj, bpprecondattr, bpprecondstate = bpprecond\n",
        "    eveffectobj, eveffectattr, eveffectstate = eveffect\n",
        "\n",
        "    if pred_plaus == correct_answer: \n",
        "      correct += 1\n",
        "      #print(spl[confl_id]['breakpoint'], bp, spl[confl_id]['confl_sents'], ev)\n",
        "      if (spl[confl_id]['breakpoint'] == bp and (ev-1) in spl[confl_id]['confl_sents']) or ((ev, bp) in spl[confl_id]['confl_sents']):\n",
        "        consis += 1\n",
        "\n",
        "        #print(spl[confl_id]['states'][bp], bpprecondobj, bpprecondattr)\n",
        "        #print(spl[confl_id]['states'][ev], eveffectobj, eveffectattr)\n",
        "\n",
        "        #need to force non-default here\n",
        "        if bpprecondstate == sc_to_precond[get_sc(spl[confl_id]['states'][bp], bpprecondobj, bpprecondattr)] \\\n",
        "          and eveffectstate == sc_to_effect[get_sc(spl[confl_id]['states'][ev-1], eveffectobj, eveffectattr)] \\\n",
        "          and eveffectstate != attr_defaults[attr]:\n",
        "          verif += 1\n",
        "\n",
        "    total += 1\n",
        "print('accuracy: %.1f%%' % (100*correct/total))\n",
        "print('consistency: %.1f%% (relative to acc: %.1f%%)' % (100*consis/total, 100*consis/correct))\n",
        "print('verifiability: %.1f%% (relative to acc: %.1f%%)' % (100*verif/total, 100*verif/correct))"
      ],
      "metadata": {
        "id": "KWHVeqfkvvUk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}